{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9624838,"sourceType":"datasetVersion","datasetId":5875043},{"sourceId":172756,"sourceType":"modelInstanceVersion","modelInstanceId":147062,"modelId":169585}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom ultralytics import YOLO\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import precision_recall_curve, f1_score\nfrom tqdm import tqdm\n\n# Parameters\nimg_height, img_width = 299, 299\nbatch_size = 32\nl2_lambda = 0.001  # L2 regularization strength\n\n# Load the CSV files\ntrain_csv = '/kaggle/input/candataset/train/_classes.csv'\nvalid_csv = '/kaggle/input/candataset/valid/_classes.csv'\ntrain_df = pd.read_csv(train_csv)\nvalid_df = pd.read_csv(valid_csv)\n\n# Remove extra whitespace from column names\ntrain_df.columns = train_df.columns.str.strip()\nvalid_df.columns = valid_df.columns.str.strip()\n\n# Columns for the labels\ny_columns = ['Critical Defect', 'Major Defect', 'Minor Defect', 'No defect']\n\n# Load YOLO model for cropping\nyolo_model = YOLO('/kaggle/input/can-detection/pytorch/default/1/best.pt')\n\ndef crop_image_using_yolo(image_path):\n    \"\"\"\n    Detect and crop can from image using YOLOv8\n    \"\"\"\n    image = cv2.imread(image_path)\n    if image is None:\n        return None\n    \n    results = yolo_model(image)\n    \n    if len(results[0].boxes) > 0:\n        box = results[0].boxes[0]\n        confidence = float(box.conf)\n        \n        if confidence > 0.5:\n            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n            cropped_image = image[y1:y2, x1:x2]\n            \n            if cropped_image.size > 0:\n                return cv2.resize(cropped_image, (img_width, img_height))\n    \n    return None\n\ndef process_and_crop_images(df, source_dir):\n    \"\"\"\n    Process all images in the dataframe using YOLO detection silently.\n    \"\"\"\n    updated_filenames = []\n    cropped_count = 0\n    total_count = len(df)\n\n    for _, row in df.iterrows():\n        image_filename = row['filename']\n        image_path = os.path.join(source_dir, image_filename)\n\n        cropped_image = crop_image_using_yolo(image_path)\n\n        if cropped_image is not None:\n            cv2.imwrite(image_path, cropped_image)\n            cropped_count += 1\n\n        updated_filenames.append(image_filename)\n\n    df['filename'] = updated_filenames\n    return df, cropped_count, total_count\n\n# Process and crop the training and validation datasets\nprint(\"Processing training images...\")\ntrain_df, train_cropped_count, train_total_count = process_and_crop_images(train_df, '/kaggle/input/candataset/train')\nprint(\"\\nProcessing validation images...\")\nvalid_df, valid_cropped_count, valid_total_count = process_and_crop_images(valid_df, '/kaggle/input/candataset/valid')\n\n# Print summary of cropping results\nprint(f\"\\nTraining set: Cropped {train_cropped_count} out of {train_total_count} images\")\nprint(f\"Validation set: Cropped {valid_cropped_count} out of {valid_total_count} images\")\n\n# Data augmentation for training data\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\n# Prepare generators for training and validation\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory='/kaggle/input/candataset/train',\n    x_col='filename',\n    y_col=y_columns,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='raw'\n)\nvalid_generator = valid_datagen.flow_from_dataframe(\n    dataframe=valid_df,\n    directory='/kaggle/input/candataset/valid',\n    x_col='filename',\n    y_col=y_columns,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='raw'\n)\n\n# Build the Xception model for classification with regularization\nbase_model = Xception(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    BatchNormalization(),  # Batch normalization for better training stability\n    Dense(1024, activation='relu', kernel_regularizer=l2(l2_lambda)),  # L2 regularization applied here\n    Dropout(0.5),  # Dropout for regularization, helps to prevent overfitting\n    Dense(4, activation='softmax', kernel_regularizer=l2(l2_lambda))  # L2 regularization applied to output layer\n])\nbase_model.trainable = False\n\n# Class balancing\nclass_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_generator.y), y=train_generator.y)\nclass_weight_dict = dict(zip(np.unique(train_generator.y), class_weights))\n\n# Compile the model with regularization in mind\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Train the model with class weights\nprint(\"\\nTraining with frozen base layers...\")\nhistory = model.fit(\n    train_generator,\n    epochs=4,\n    validation_data=valid_generator,\n    class_weight=class_weight_dict,\n    verbose=1\n)\n\n# Fine-tune the model\nprint(\"\\nFine-tuning the model...\")\nbase_model.trainable = True\nmodel.compile(\n    optimizer=Adam(learning_rate=0.00001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nfine_tune_history = model.fit(\n    train_generator,\n    epochs=3,\n    validation_data=valid_generator,\n    class_weight=class_weight_dict,\n    verbose=1\n)\n\n# Evaluate the model\ny_pred = model.predict(valid_generator)\nprecision, recall, thresholds = precision_recall_curve(valid_generator.y, y_pred, pos_label=1)\nf1_scores = [2 * p * r / (p + r + 1e-8) for p, r in zip(precision, recall)]\nbest_threshold = thresholds[np.argmax(f1_scores)]\nprint(f\"Best threshold: {best_threshold:.2f}\")\n\ny_pred_binary = (y_pred[:, 1] > best_threshold).astype(int)\nvalid_f1 = f1_score(valid_generator.y, y_pred_binary)\nprint(f\"Validation F1-score: {valid_f1:.4f}\")\n\n# Save the model and weights\nmodel_save_path = '/kaggle/working/candefect_model.h5'\nmodel.save(model_save_path)\nprint(f\"Model saved at {model_save_path}\")\n\nweights_save_path = '/kaggle/working/candefect_weights.weights.h5'\nmodel.save_weights(weights_save_path)\nprint(f\"Weights saved at {weights_save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom ultralytics import YOLO\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tqdm import tqdm\n\n# Paths and constants\ntest_csv = '/kaggle/input/candataset/test/_classes.csv'\ntest_dir = '/kaggle/input/candataset/test'\nmodel_path = '/kaggle/working/candefect_model.h5'\nyolo_model_path = '/kaggle/input/can-detection/pytorch/default/1/best.pt'\n\nimg_height, img_width = 299, 299\ny_columns = ['Critical Defect', 'Major Defect', 'Minor Defect', 'No defect']\n\n# Load the CSV file\ntest_df = pd.read_csv(test_csv)\ntest_df.columns = test_df.columns.str.strip()\n\n# Load trained Xception model\nmodel = load_model(model_path)\n\n# Load YOLO model for object detection\nyolo_model = YOLO(yolo_model_path)\n\n# Data generator for test data (apply the same rescale factor as used during training)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Function to crop image using YOLO\ndef crop_image_using_yolo(image_path):\n    \"\"\"\n    Detect and crop can from image using YOLOv8.\n    Resizes the cropped region to the desired input size for the classifier.\n    \"\"\"\n    image = cv2.imread(image_path)\n    if image is None:\n        print(f\"Error: Image at {image_path} not found.\")\n        return None, None\n    \n    # Run YOLO prediction to find objects in the image\n    results = yolo_model(image)\n    \n    if len(results[0].boxes) > 0:\n        # Take the first detected box\n        box = results[0].boxes[0]\n        confidence = float(box.conf)\n        \n        if confidence > 0.5:\n            # Extract bounding box coordinates\n            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n            \n            # Crop the image using bounding box coordinates\n            cropped_image = image[y1:y2, x1:x2]\n            \n            if cropped_image.size > 0:\n                # Resize cropped image to match model input size\n                cropped_image = cv2.resize(cropped_image, (img_width, img_height))\n                return cropped_image, (x1, y1, x2, y2)\n    \n    # If no valid detection, return None\n    print(f\"No valid detection for {image_path}\")\n    return None, None\n\n# Predict and draw bounding boxes\ndef predict_and_draw_bboxes(test_df, source_dir, model):\n    \"\"\"\n    Predict defects using the Xception model and draw bounding boxes.\n    \"\"\"\n    true_labels = []\n    predicted_labels = []\n    incorrect_indices = []\n    correct_indices = []\n\n    with tqdm(total=len(test_df), desc=\"Processing test images\") as pbar:\n        for idx, row in test_df.iterrows():\n            image_filename = row['filename']\n            true_label = row[y_columns].values  # Ground truth labels\n            image_path = os.path.join(source_dir, image_filename)\n\n            # Crop the image using YOLO\n            cropped_image, bbox_coords = crop_image_using_yolo(image_path)\n\n            if cropped_image is not None:\n                # Rescale the image after resizing (value range 0-1)\n                cropped_image = cropped_image / 255.0\n                cropped_image = np.expand_dims(cropped_image, axis=0)\n\n                # Predict using the trained Xception model\n                prediction = model.predict(cropped_image)\n                predicted_label = np.argmax(prediction, axis=1)[0]\n                true_label_idx = np.argmax(true_label)\n\n                # Record true and predicted labels\n                true_labels.append(true_label_idx)\n                predicted_labels.append(predicted_label)\n\n                # Determine correct or incorrect prediction\n                if true_label_idx == predicted_label:\n                    correct_indices.append(idx)\n                else:\n                    incorrect_indices.append(idx)\n\n                # Draw bounding box on the original image if available\n                if bbox_coords is not None:\n                    x1, y1, x2, y2 = bbox_coords\n                    image = cv2.imread(image_path)\n                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n                    label_text = f\"Pred: {y_columns[predicted_label]}, True: {y_columns[true_label_idx]}\"\n                    cv2.putText(image, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n                    # Save the image with bounding box if needed\n                    output_path = f\"/kaggle/working/results/{image_filename}\"\n                    cv2.imwrite(output_path, image)\n\n            pbar.update(1)\n\n    return true_labels, predicted_labels, correct_indices, incorrect_indices\n\n# Process test images and make predictions\nprint(\"Processing test images and making predictions...\")\ntrue_labels, predicted_labels, correct_indices, incorrect_indices = predict_and_draw_bboxes(test_df, test_dir, model)\n\n# Calculate accuracy and other metrics\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy on the test set: {accuracy:.4f}\")\n\n# Generate a classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_labels, predicted_labels, target_names=y_columns))\n\n# Function to plot images\ndef plot_images(indices, title, test_df, directory):\n    plt.figure(figsize=(16, 16))\n    for i, idx in enumerate(indices[:9]):\n        filename = test_df.iloc[idx]['filename']\n        image_path = os.path.join(directory, filename)\n        image = cv2.imread(image_path)\n        if image is not None:\n            plt.subplot(3, 3, i + 1)\n            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n            plt.title(f\"{title}\\n{filename}\")\n            plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Plot incorrect predictions\nprint(\"\\nPlotting incorrect predictions...\")\nplot_images(incorrect_indices, \"Incorrect Predictions\", test_df, test_dir)\n\n# Plot correct predictions\nprint(\"\\nPlotting correct predictions...\")\nplot_images(correct_indices, \"Correct Predictions\", test_df, test_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Ý CẦN CẢI TIẾN\n\nModel này chủ yếu dựa vào hình dạng của lon để phân loại hình dạng của lon nhưng chưa dựa vào tình trạng của lon như thế nào, đa phần những ảnh mà model dự đoán sai là do lon đã bị rỉ sét nặng, nên phải là Major defect, nhưng model đa phần dự đoán là minor defect. Có thể sử dụng Canny để phát hiện những bất thường trên bề mặt lon, Grad-CAM để hiển thị khu vực mà model đang chú ý có thể giúp nhận ra rằng model có thể không chú ý đến khu vực bị rỉ sét,...","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}